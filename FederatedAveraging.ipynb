{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02333dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import collections\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from tensorflow import TensorSpec\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow_federated.python.simulation.datasets import ClientData\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610975d",
   "metadata": {},
   "source": [
    "**We start by downloading the MNIST dataset provided by TensorFlow Federated. This data includes the client_ids (i.e. the ID of the client that generated the handwritten digit), allowing for a simulation of the \"only positive labels\" setting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28b5d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = tff.simulation.datasets.emnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c98072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3383"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of clients \n",
    "len(train.client_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d32f4d61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int32, name=None)),\n",
       "             ('pixels',\n",
       "              TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.element_type_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d15cdd",
   "metadata": {},
   "source": [
    "**We then convert the MNIST dataset to a federated dataset in which each client only has samples from a single class. This is in order to simulate the \"only positive labels\" setting in which each client only has access to positives from one class. We choose the most frequent label per client dataset (taken from *most_frequent_labels.json*) to be the positive label for the client. We keep in mind that the overall problem setting is still that of multi-class classification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d3c22cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('most_frequent_labels.json')\n",
    "d = json.load(f)\n",
    "d2 = {}\n",
    "for k, v in d.items(): \n",
    "    d2[train.client_ids[int(k)]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eebde836",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "\n",
    "def preprocess(dataset):\n",
    "    def helper(element):\n",
    "        x=tf.reshape(element['pixels'], [-1, 784])\n",
    "        y=tf.reshape(element['label'], [-1, 1])\n",
    "        return collections.OrderedDict(x=x,y=y)\n",
    "\n",
    "    return dataset.batch(BATCH_SIZE).map(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c174e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aux(client_id):\n",
    "    dataset = train.create_tf_dataset_for_client(client_id)\n",
    "    out = preprocess(dataset)\n",
    "    out = next(iter(out))\n",
    "    xs = out['x']\n",
    "    ys = out['y']\n",
    "    \n",
    "    y_ind = tf.where(ys == d2[client_id]) \n",
    "    # d2[client_id] corresponds to the most frequent label in that client dataset\n",
    "    gathered_ys = tf.gather_nd(ys, y_ind)\n",
    "    \n",
    "    x_ind = y_ind[:, 0]\n",
    "    gathered_xs = tf.gather(xs, x_ind)\n",
    "    \n",
    "    return OrderedDict([('x', gathered_xs), ('y', gathered_ys)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8133d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_fn(client_id): \n",
    "    store = aux(client_id)\n",
    "    return Dataset.from_tensor_slices({'x': store['x'], 'y': store['y']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d711aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = ClientData.from_clients_and_tf_fn(train.client_ids, dt_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bde5a91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3383"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLIENTS = len(cd.client_ids)\n",
    "NUM_CLIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa4e5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess2(dataset):\n",
    "    def batch_format_fn(element):\n",
    "        \"\"\"Flatten a batch `pixels` and return the features as an `OrderedDict`.\"\"\"\n",
    "        return collections.OrderedDict(\n",
    "            x=tf.reshape(element['x'], [-1, 784]),\n",
    "            y=tf.reshape(element['y'], [-1, 1]))\n",
    "\n",
    "    return dataset.batch(BATCH_SIZE).map(batch_format_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a347efd1",
   "metadata": {},
   "source": [
    "**We now make additional arrangements to simulate a federated training environment. In a typical federated training scenario, we deal with a potentially very large population of user devices. Of these devices, only a fraction may be available for training (mobile phone connected to internet, charging, etc.) at a given point in time. To simulate this volatility, we sample a random subset of the clients to be involved in each round of training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41f4e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_federated_data(client_data, client_ids):\n",
    "    return [preprocess2(client_data.create_tf_dataset_for_client(x))\n",
    "      for x in client_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98c90298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "    return tf.keras.models.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape=(784,)),\n",
    "      tf.keras.layers.Dense(10, kernel_initializer='zeros'),\n",
    "      tf.keras.layers.Softmax(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01aecff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "  # We _must_ create a new model here, and _not_ capture it from an external\n",
    "  # scope. TFF will call this within different graph contexts.\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "      keras_model,\n",
    "      input_spec=OrderedDict([('x', TensorSpec(shape=(None, 28*28), \n",
    "                                               dtype=tf.float32, name=None)),\n",
    "                             ('y', TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))]),\n",
    "                              \n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b760bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afe18748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( -> <\n",
      "  global_model_weights=<\n",
      "    trainable=<\n",
      "      float32[784,10],\n",
      "      float32[10]\n",
      "    >,\n",
      "    non_trainable=<>\n",
      "  >,\n",
      "  distributor=<>,\n",
      "  client_work=<>,\n",
      "  aggregator=<\n",
      "    value_sum_process=<>,\n",
      "    weight_sum_process=<>\n",
      "  >,\n",
      "  finalizer=<\n",
      "    int64\n",
      "  >\n",
      ">@SERVER)\n"
     ]
    }
   ],
   "source": [
    "print(training_process.initialize.type_signature.formatted_representation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55696799",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_state = training_process.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90908fb",
   "metadata": {},
   "source": [
    "**The volatility simulation happens here: at each round of training, we choose a random integer N between 10 and 20 as the number of participants in the training round. We then construct the federated train data for that round by choosing N client_ids.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e5e6158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_for_round(): \n",
    "    N = np.random.randint(10, 20)\n",
    "    chosen_client_ids = np.random.randint(0, NUM_CLIENTS, N)\n",
    "    chosen = [cd.client_ids[i] for i in chosen_client_ids]\n",
    "    return make_federated_data(cd, chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7c7cc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 01:36:44.168033: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-20 01:36:44.173291: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    }
   ],
   "source": [
    "# first round\n",
    "federated_train_data = create_data_for_round()\n",
    "result = training_process.next(train_state, federated_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d53471cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round  1, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.058558557), ('loss', 2.302585), ('num_examples', 222), ('num_batches', 18)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\n"
     ]
    }
   ],
   "source": [
    "train_state = result.state\n",
    "train_metrics = result.metrics\n",
    "print('round  1, metrics={}'.format(train_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a487546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating federated train data for round\n",
      "Starting next round\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 01:37:01.086267: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-20 01:37:01.097159: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluded round  2\n",
      "round  2, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.3710692), ('loss', 2.1616848), ('num_examples', 159), ('num_batches', 13)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\n",
      "Creating federated train data for round\n",
      "Starting next round\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 01:37:09.007902: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n",
      "2022-12-20 01:37:09.040260: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluded round  3\n",
      "round  3, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.08275862), ('loss', 2.5953817), ('num_examples', 145), ('num_batches', 12)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\n",
      "Creating federated train data for round\n",
      "Starting next round\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 01:37:17.398570: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluded round  4\n",
      "round  4, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.42276424), ('loss', 4.213967), ('num_examples', 246), ('num_batches', 19)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\n",
      "Creating federated train data for round\n",
      "Starting next round\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 01:37:24.706210: W tensorflow/core/data/root_dataset.cc:266] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluded round  5\n",
      "round  5, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.14606741), ('loss', 3.1807973), ('num_examples', 178), ('num_batches', 14)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\n",
      "Creating federated train data for round\n",
      "Starting next round\n",
      "Concluded round  6\n",
      "round  6, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.15243903), ('loss', 2.1013474), ('num_examples', 164), ('num_batches', 13)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\n",
      "Creating federated train data for round\n",
      "Starting next round\n",
      "Concluded round  7\n",
      "round  7, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.54404145), ('loss', 2.1113176), ('num_examples', 193), ('num_batches', 15)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\n",
      "Creating federated train data for round\n",
      "Starting next round\n",
      "Concluded round  8\n",
      "round  8, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.0), ('loss', 3.2797337), ('num_examples', 149), ('num_batches', 12)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\n",
      "Creating federated train data for round\n",
      "Starting next round\n",
      "Concluded round  9\n",
      "round  9, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.54037267), ('loss', 2.95663), ('num_examples', 161), ('num_batches', 13)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\n",
      "Creating federated train data for round\n",
      "Starting next round\n",
      "Concluded round 10\n",
      "round 10, metrics=OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('sparse_categorical_accuracy', 0.05), ('loss', 3.8030517), ('num_examples', 140), ('num_batches', 12)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', ())])\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 11\n",
    "for round_num in range(2, NUM_ROUNDS):\n",
    "    print(\"Creating federated train data for round\")\n",
    "    federated_train_data = create_data_for_round()\n",
    "    print(\"Starting next round\")\n",
    "    result = training_process.next(train_state, federated_train_data)\n",
    "    print(\"Concluded round {:2d}\".format(round_num))\n",
    "    train_state = result.state\n",
    "    train_metrics = result.metrics\n",
    "    print('round {:2d}, metrics={}'.format(round_num, train_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57636ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
